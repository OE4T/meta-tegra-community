From 04cd040ec80588ccdc338d4afbf9ffc08dfc1db4 Mon Sep 17 00:00:00 2001
From: Ilies CHERGUI <ichergui@nvidia.com>
Date: Mon, 13 Oct 2025 10:04:43 +0100
Subject: [PATCH 7/7] Updates for OE cross builds

Upstream-Status: Inappropriate [OE-specific]
Signed-off-by: Ilies CHERGUI <ichergui@nvidia.com>
---
 modules/holoinfer/src/CMakeLists.txt      |  4 ++++
 modules/holoviz/src/glfw_window.cpp       |  2 +-
 modules/holoviz/src/vulkan/vulkan_app.cpp | 14 +++++++-------
 3 files changed, 12 insertions(+), 8 deletions(-)

diff --git a/modules/holoinfer/src/CMakeLists.txt b/modules/holoinfer/src/CMakeLists.txt
index cc1e1ac..09dd40a 100644
--- a/modules/holoinfer/src/CMakeLists.txt
+++ b/modules/holoinfer/src/CMakeLists.txt
@@ -121,6 +121,10 @@ target_link_libraries(${PROJECT_NAME}
 #     get rid of the holoscan::infer_utils target which could be merged back in holoinfer. The point
 #     of this comment was to highlight the current architecture which can appear confusing otherwise.
 
+target_compile_options(${PROJECT_NAME} PRIVATE
+    $<$<COMPILE_LANGUAGE:CUDA>:-Xcompiler=-Wno-error=deprecated-declarations>
+)
+
 if(HOLOSCAN_BUILD_LIBTORCH)
     # no target_link_libraries to holoinfer_torch: we dlopen it as a plugin
     target_compile_definitions(${PROJECT_NAME} PUBLIC "HOLOINFER_TORCH_ENABLED")
diff --git a/modules/holoviz/src/glfw_window.cpp b/modules/holoviz/src/glfw_window.cpp
index d979417..f0a48e7 100644
--- a/modules/holoviz/src/glfw_window.cpp
+++ b/modules/holoviz/src/glfw_window.cpp
@@ -592,7 +592,7 @@ vk::SurfaceKHR GLFWWindow::create_surface(vk::PhysicalDevice physical_device,
   VkSurfaceKHR surface;
   const vk::Result result =
       vk::Result(glfwCreateWindowSurface(instance, impl_->window_, nullptr, &surface));
-  vk::resultCheck(result, "Failed to create glfw window surface");
+  vk::detail::resultCheck(result, "Failed to create glfw window surface");
   return surface;
 }
 
diff --git a/modules/holoviz/src/vulkan/vulkan_app.cpp b/modules/holoviz/src/vulkan/vulkan_app.cpp
index d9838d8..fcbc706 100644
--- a/modules/holoviz/src/vulkan/vulkan_app.cpp
+++ b/modules/holoviz/src/vulkan/vulkan_app.cpp
@@ -797,7 +797,7 @@ void Vulkan::Impl::end_transfer_pass() {
   // submit staged transfers
   const vk::Result result =
       vk::Result(nvvk_.transfer_batch_submission_.execute(transfer_job.fence_.get(), 0b0000'0001));
-  vk::resultCheck(result, "Failed to execute batch submission");
+  vk::detail::resultCheck(result, "Failed to execute batch submission");
 
   // next graphics submission must wait for transfer completion
   nvvk_.batch_submission_.enqueueWait(transfer_job.semaphore_.get(),
@@ -866,7 +866,7 @@ void Vulkan::Impl::cleanup_transfer_jobs() {
 
         it->fence_triggered_ = true;
       } else if (result != vk::Result::eNotReady) {
-        vk::resultCheck(result, "Failed to get upload fence status");
+        vk::detail::resultCheck(result, "Failed to get upload fence status");
       }
     }
 
@@ -884,7 +884,7 @@ void Vulkan::Impl::cleanup_transfer_jobs() {
           it = next;
           continue;
         } else if (result != vk::Result::eNotReady) {
-          vk::resultCheck(result, "Failed to get frame fence status");
+          vk::detail::resultCheck(result, "Failed to get frame fence status");
         }
       } else {
         // this is a stale transfer buffer (no end_transfer_pass()?), remove it
@@ -917,7 +917,7 @@ void Vulkan::Impl::prepare_frame() {
   if (result != vk::Result::eSuccess) {
     // This allows Aftermath to do things and exit below
     usleep(1000);
-    vk::resultCheck(result, "Failed to wait for frame fences");
+    vk::detail::resultCheck(result, "Failed to wait for frame fences");
     exit(-1);
   }
 
@@ -949,7 +949,7 @@ void Vulkan::Impl::submit_frame() {
 
   const vk::Result result =
       vk::Result(nvvk_.batch_submission_.execute(wait_fences_[image_index].get(), 0b0000'0001));
-  vk::resultCheck(result, "Failed to execute batch submission");
+  vk::detail::resultCheck(result, "Failed to execute batch submission");
 
   // Presenting frame
   fb_sequence_->present(queue_gct_);
@@ -2222,7 +2222,7 @@ void Vulkan::Impl::read_framebuffer(Vulkan* vulkan, ImageFormat fmt, uint32_t wi
     if (result != vk::Result::eSuccess) {
       // This allows Aftermath to do things and exit below
       usleep(1000);
-      vk::resultCheck(result, "Failed to wait for frame fences");
+      vk::detail::resultCheck(result, "Failed to wait for frame fences");
       exit(-1);
     }
 
@@ -2279,7 +2279,7 @@ void Vulkan::Impl::read_framebuffer(Vulkan* vulkan, ImageFormat fmt, uint32_t wi
   // submit the command buffer
   const vk::Result result =
       vk::Result(nvvk_.batch_submission_.execute(read_job.fence_.get(), 0b0000'0001));
-  vk::resultCheck(result, "Failed to execute batch submission");
+  vk::detail::resultCheck(result, "Failed to execute batch submission");
 
   // copy the buffer to CUDA memory
   {
-- 
2.34.1

