From c98b0f5c0b01439fe05d40e02a7a368c079a68bc Mon Sep 17 00:00:00 2001
From: Ilies CHERGUI <ilies.chergui@gmail.com>
Date: Sat, 22 Jul 2023 15:05:32 +0100
Subject: [PATCH 1/2] Build fixups

Signed-off-by: Ilies CHERGUI <ilies.chergui@gmail.com>
Signed-off-by: Roger Knecht <roger@norberthealth.com>
---
 CMakeLists.txt  | 35 ++++++++++++-----------------------
 src/tensorrt.cc |  2 +-
 2 files changed, 13 insertions(+), 24 deletions(-)

diff --git a/CMakeLists.txt b/CMakeLists.txt
index 5da6ecd..11ee8b0 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -46,7 +46,7 @@ if(NOT CMAKE_BUILD_TYPE)
 endif()
 
 set(TRITON_TENSORRT_BACKEND_LIBNAME triton_tensorrt)
-set(TRITON_TENSORRT_BACKEND_INSTALLDIR ${CMAKE_INSTALL_PREFIX}/backends/tensorrt)
+set(TRITON_TENSORRT_BACKEND_INSTALLDIR ${CMAKE_INSTALL_LIBDIR}/tensorrt)
 
 #
 # Dependencies
@@ -54,30 +54,14 @@ set(TRITON_TENSORRT_BACKEND_INSTALLDIR ${CMAKE_INSTALL_PREFIX}/backends/tensorrt
 # FetchContent's composibility isn't very good. We must include the
 # transitive closure of all repos so that we can override the tag.
 #
-include(FetchContent)
-
-FetchContent_Declare(
-  repo-common
-  GIT_REPOSITORY https://github.com/triton-inference-server/common.git
-  GIT_TAG ${TRITON_COMMON_REPO_TAG}
-)
-FetchContent_Declare(
-  repo-core
-  GIT_REPOSITORY https://github.com/triton-inference-server/core.git
-  GIT_TAG ${TRITON_CORE_REPO_TAG}
-)
-FetchContent_Declare(
-  repo-backend
-  GIT_REPOSITORY https://github.com/triton-inference-server/backend.git
-  GIT_TAG ${TRITON_BACKEND_REPO_TAG}
-)
-FetchContent_MakeAvailable(repo-common repo-core repo-backend)
 
 #
 # CUDA
 #
 if(${TRITON_ENABLE_GPU})
-  find_package(CUDAToolkit REQUIRED)
+  enable_language(CUDA)
+  find_package(CUDA REQUIRED)
+  include_directories(${CUDA_INCLUDE_DIRS})
   message(STATUS "Using CUDA ${CUDA_VERSION}")
   set(CUDA_NVCC_FLAGS -std=c++11)
 
@@ -178,9 +162,14 @@ find_library(NVINFER_PLUGIN_LIBRARY NAMES nvinfer_plugin)
 target_link_libraries(
   triton-tensorrt-backend
   PRIVATE
-    triton-core-serverapi   # from repo-core
-    triton-core-serverstub  # from repo-core
+    triton-common-async-work-queue
+    triton-common-error
+    triton-common-logging
+    triton-common-model-config
+    triton-common-table-printer
     triton-backend-utils    # from repo-backend
+    kernel-library-new
+    triton-core             # from repo-core
     -lpthread
     ${NVINFER_LIBRARY}
     ${NVINFER_PLUGIN_LIBRARY}
@@ -194,7 +183,7 @@ target_link_libraries(
 target_link_libraries(
     triton-tensorrt-backend
     PRIVATE
-      CUDA::cudart
+      cudart
 )
 
 
diff --git a/src/tensorrt.cc b/src/tensorrt.cc
index 65f62d3..736ef15 100644
--- a/src/tensorrt.cc
+++ b/src/tensorrt.cc
@@ -2553,7 +2553,7 @@ ModelInstanceState::ProcessResponse()
 {
   while (true) {
     NVTX_RANGE(nvtx_, "ProcessResponse " + Name());
-    auto payload = std::move(completion_queue_.Get());
+    auto payload = completion_queue_.Get();
     if (payload.get() == nullptr) {
       break;
     }
-- 
2.25.1

